{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "The file  ğš–ğš¢ğšœğšğšğš›ğš¢.ğšğšŠğš  contains pairs  (ğ‘¥,ğ‘¦) , where  ğ‘¥âˆˆâ„100  and  ğ‘¦âˆˆâ„ . There is one data point per line, with comma-separated values; the very last number in each line is the  ğ‘¦ -value.\n",
    "\n",
    "In this data set,  ğ‘¦  is a linear function of just ten of the features in  ğ‘¥ , plus some noise. Your job is to identify those ten features.\n",
    "\n",
    "Which of the following contain only relevant features?\n",
    "\n",
    "(Think of the feature numbers as being in the range 1 to 100, but be aware that Python indexes arrays starting at zero.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Routines for linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('mystery.dat', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,0:100]\n",
    "y = data[:,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_subset_regression(x,y,flist):\n",
    "    if len(flist) < 1:\n",
    "        print(\"Need at least one feature\")\n",
    "        return\n",
    "    for f in flist:\n",
    "        if (f < 0) or (f > 100):\n",
    "            print(\"Feature index is out of bounds\")\n",
    "            return\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x[:,flist], y)\n",
    "    return mean_squared_error(y, regr.predict(x[:,flist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666805964795619\n",
      "5.931005043656825\n",
      "6.711275934495151\n",
      "7.497074872393358\n"
     ]
    }
   ],
   "source": [
    "feature_list=[[0,4,6,18,43],[1,2,12,16,28],[2,6,12,18,43],[4,22,23,50,60]] #We are subtracting 1 from every index\n",
    "for features in feature_list:\n",
    "    print(feature_subset_regression(x,y,features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provides correct answer. Let's try single features to get top 10 features with lowest MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_feature_regression(x,y,f):\n",
    "    if (f < 0) or (f > 99):\n",
    "        print(\"Feature index is out of bounds\")\n",
    "        return 0\n",
    "    regr = linear_model.LinearRegression()\n",
    "    x1 = x[:,[f]]\n",
    "    regr.fit(x1, y)\n",
    "    # Make predictions using the model\n",
    "    y_pred = regr.predict(x1)\n",
    "    #print(\"Mean squared error: \", mean_squared_error(y, y_pred))\n",
    "    return mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ten_singled_features(x,y):\n",
    "    ls=[]\n",
    "    indices=[]\n",
    "    for i in range(0,100):\n",
    "        ls.append(one_feature_regression(x,y,i))\n",
    "    sorted_ls=sorted(ls)\n",
    "    #[i+1 for i,x in enumerate(ls) if x=min(ls)]\n",
    "    for x in sorted_ls:\n",
    "        indices.append(ls.index(x))\n",
    "    return indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get MSE for [16, 10, 18, 22, 12, 25, 4, 80, 6, 1] features as  2.135608858468031\n"
     ]
    }
   ],
   "source": [
    "indices= top_ten_singled_features(x,y)\n",
    "print(\"We get MSE for\",indices,\"features as \",feature_subset_regression(x,y,indices)) # Add 1 to relate with answers given"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
